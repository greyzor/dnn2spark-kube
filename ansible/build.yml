---
  - hosts: localhost
    connection: local
    user: root

    vars:
      nb: "{{notebook}}"

    tasks:

      - name: create build directory
        file:
          path: "{{ item }}"
          state: directory
        with_items:
          - ../build/python/scripts
          - ../build/spark/

      # The notebook should have the right extension.
      - assert: { that: nb | match(".*\.ipynb") }

      # ---------------- Notebooks ----------------#
      - name: convert the notebook to a python script.
        shell: jupyter nbconvert --to script {{nb}} --output=../build/python/scripts/{{(notebook | regex_replace('^.*\/(.*)$', '\1') | splitext)[0]}}
        args:
          chdir: ../

      #---------------- Spark ----------------#
      - name: Download Spark 2.4x
        get_url:
          url: https://www-us.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz
          dest: ../build/spark/
          mode: '0755'

      - name: Extract Spark source
        shell: tar -xvzf spark-2.4.3-bin-hadoop2.7.tgz
        args:
          chdir: ../build/spark/

      # ---------------- Docker image for Spark/Kubernetes ----------------#
      # 1. build base image
      # - name: Build Spark image for Kubernetes from official sources, no push.
      #   command: docker build -t spark:latest -f kubernetes/dockerfiles/spark/Dockerfile .
      #   args:
      #     chdir: ../build/spark/spark-2.4.3-bin-hadoop2.7/

      - name: Install docker-py
        pip: name=docker-py
        become: yes

      # workaround for: docker (ADD/COPY) forbidden path outside the build context.
      - name: Copy py_scripts inside docker context.
        copy:
          src: ../build/python/scripts/
          dest: ../docker/py_scripts/

      - name: Create spark directory for docker build (redundant copy since added files must be in docker context)
        file:
          path: ../docker/spark
          state: directory

      # prepare spark for docker build
      - name: Copy spark inside docker context.
        copy:
          src: ../build/spark/spark-2.4.3-bin-hadoop2.7/{{ item }}
          dest: ../docker/spark/{{ item }}
        with_items:
          - jars/
          - bin/
          - sbin/
          - kubernetes/dockerfiles/spark/entrypoint.sh
          - examples
          - /kubernetes/tests
          - data/

      # patch entrypoint.sh
      - name: Patch entrypoint, official one was for alpine while we are building a ubuntu/deb based image.
        copy:
          src: ../docker/entrypoint.sh
          dest: ../docker/spark/kubernetes/dockerfiles/spark/entrypoint.sh

      # docker build
      - name: Build docker image for spark+keras.
        command: docker build -t spark-keras-nb -f Dockerfile .
        args:
          chdir: ../docker